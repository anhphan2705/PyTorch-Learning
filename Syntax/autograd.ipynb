{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "    - Neural Networks (NN) are a collection of nested functions that are executed on some input data. These functions are defined by parameters (consisting of weights and biases), which in PyTorch are stored in tensors\n",
    "    - Training a NN happens in 2 steps:\n",
    "        + Forward Propagation\n",
    "            In forward prop, the NN makes its best guest about the correct output. It runs the input data through eaech of its functions to make this guess\n",
    "        + Backward Propagation\n",
    "            In backdrop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collection the derivatives of the error with respect to the parameters of the functions (gradient), and optimizing the parameters using gradient decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage in PyTorch\n",
    "    - Look at an example in a single training step\n",
    "    - Load a pretrained resnet18 model from `torchvision`\n",
    "    - Create a random data tensor to represent a single image with 3 channels, and height & width of 64, and its corresponding label initialized to some random values.\n",
    "    - Label in pretrained model has shape (1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7945, 0.9212, 0.0086,  ..., 0.2584, 0.1421, 0.5565],\n",
      "          [0.6169, 0.1654, 0.6131,  ..., 0.1511, 0.1739, 0.5895],\n",
      "          [0.6667, 0.9735, 0.9086,  ..., 0.5483, 0.1277, 0.9722],\n",
      "          ...,\n",
      "          [0.7525, 0.6982, 0.4203,  ..., 0.9707, 0.6118, 0.3621],\n",
      "          [0.5401, 0.0985, 0.5641,  ..., 0.2159, 0.8793, 0.3070],\n",
      "          [0.0022, 0.8326, 0.3665,  ..., 0.8551, 0.1750, 0.9269]],\n",
      "\n",
      "         [[0.9343, 0.6186, 0.5230,  ..., 0.8610, 0.0111, 0.7296],\n",
      "          [0.4398, 0.5608, 0.9776,  ..., 0.3988, 0.8763, 0.1165],\n",
      "          [0.5559, 0.1368, 0.8587,  ..., 0.0586, 0.2351, 0.9759],\n",
      "          ...,\n",
      "          [0.0815, 0.5179, 0.0743,  ..., 0.4192, 0.9677, 0.0203],\n",
      "          [0.3231, 0.8134, 0.7592,  ..., 0.2977, 0.1579, 0.8583],\n",
      "          [0.4822, 0.8466, 0.4989,  ..., 0.9467, 0.9577, 0.7412]],\n",
      "\n",
      "         [[0.1369, 0.6842, 0.7579,  ..., 0.7408, 0.1384, 0.3745],\n",
      "          [0.2588, 0.0715, 0.4255,  ..., 0.4197, 0.0072, 0.5791],\n",
      "          [0.4399, 0.2203, 0.3946,  ..., 0.2932, 0.0345, 0.0711],\n",
      "          ...,\n",
      "          [0.7689, 0.6425, 0.3591,  ..., 0.5783, 0.2743, 0.4536],\n",
      "          [0.8833, 0.7444, 0.9049,  ..., 0.7235, 0.3231, 0.6576],\n",
      "          [0.6993, 0.0729, 0.6021,  ..., 0.1406, 0.6622, 0.8852]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foward pass\n",
    "    - Run input data through the model through each of its layers to make a prediction\n",
    "    - This is a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.9497e-01, -3.7642e-01, -6.6297e-01, -1.8168e+00, -9.5568e-01,\n",
      "         -2.4242e-01, -6.4858e-01,  5.8965e-01,  3.1449e-01, -1.2833e+00,\n",
      "         -9.9062e-01, -1.0028e+00, -7.0625e-01, -1.3250e+00, -1.4976e+00,\n",
      "         -5.8581e-01, -9.7423e-01, -5.9386e-01, -8.8387e-01, -7.8455e-01,\n",
      "         -1.7550e+00, -7.6758e-01, -1.7041e+00, -1.5296e-01, -1.3841e+00,\n",
      "         -1.0366e+00, -5.8035e-01, -1.0775e+00, -7.5102e-01, -3.4078e-01,\n",
      "         -8.0396e-01, -7.7026e-01, -2.8365e-01, -5.3995e-01, -2.7314e-01,\n",
      "         -3.4115e-01,  7.8332e-01, -5.2909e-01, -3.5916e-01,  7.7009e-02,\n",
      "         -9.8506e-01, -8.0531e-01, -1.1481e+00, -6.7082e-01, -6.4001e-01,\n",
      "         -3.4048e-01, -8.1694e-01, -3.9585e-01, -1.3631e+00, -1.1054e+00,\n",
      "         -7.8536e-01,  3.9908e-01, -2.5636e-01, -4.4092e-01,  1.5435e-02,\n",
      "         -1.1366e+00, -2.1440e-01, -1.3917e+00, -5.8990e-01, -4.1031e-01,\n",
      "          6.6778e-01, -9.7795e-02, -1.9884e-01,  3.4840e-01, -9.2255e-01,\n",
      "         -3.4091e-01, -3.5348e-01, -4.7300e-01, -7.1685e-01, -1.1446e+00,\n",
      "         -1.8059e+00,  4.6462e-01, -1.4536e+00, -4.2654e-01, -1.3552e+00,\n",
      "         -1.2059e+00,  7.2824e-02, -7.0771e-01,  2.0441e-01,  1.9524e-01,\n",
      "         -7.8815e-01, -1.6577e+00,  1.6194e-02, -6.5639e-01, -8.1606e-01,\n",
      "         -1.1683e-01,  3.4324e-01,  2.0996e-01,  1.3494e-01, -9.5169e-01,\n",
      "         -1.0171e+00, -1.2224e+00, -1.6196e+00, -2.4322e-01, -2.3367e-01,\n",
      "         -2.1858e+00, -3.8393e-01, -4.5046e-01, -1.4466e+00, -6.1491e-01,\n",
      "         -1.4740e+00, -1.2028e+00, -1.0820e+00, -5.6641e-01, -3.3571e-01,\n",
      "         -9.8352e-01, -6.8240e-01, -1.3001e+00, -1.0613e+00, -1.6379e+00,\n",
      "         -1.0184e+00, -6.1041e-01,  1.3829e+00,  6.1706e-01,  3.8232e-01,\n",
      "         -1.0019e+00, -7.2469e-01, -3.7368e-01,  5.6242e-01, -2.5621e-01,\n",
      "         -6.8834e-01,  2.7682e-01,  6.8039e-01,  6.1318e-02,  1.2140e+00,\n",
      "          8.3100e-02,  5.1829e-01, -1.3737e+00, -1.2592e+00, -1.1357e+00,\n",
      "         -1.3980e+00, -1.4312e+00, -1.0576e+00, -1.4479e+00, -7.2966e-01,\n",
      "         -1.5381e+00, -1.0767e+00, -1.3852e+00, -1.5465e+00, -1.7764e+00,\n",
      "         -1.9928e+00, -1.9166e+00, -2.5623e+00, -1.6247e+00, -1.0701e+00,\n",
      "         -2.4746e-01, -1.1183e+00, -1.8705e+00, -1.3091e+00, -1.1643e+00,\n",
      "          2.1570e-01,  1.4702e+00, -9.7813e-01, -5.9359e-01,  2.3597e-01,\n",
      "          1.3555e-01, -2.2411e-01, -1.8650e-01,  1.2282e-01,  3.8021e-01,\n",
      "          4.9119e-01,  9.5956e-01,  5.0362e-01,  9.2261e-01,  4.8293e-01,\n",
      "          1.0571e-01,  3.9350e-02, -1.7217e-01,  8.5374e-01, -1.9706e-01,\n",
      "         -1.4179e-01,  9.2096e-01,  4.5932e-01,  4.7027e-01,  4.8108e-02,\n",
      "         -6.3671e-01,  2.8489e-01, -2.0254e-01,  7.7342e-01,  6.5061e-01,\n",
      "          5.3698e-01, -2.9568e-01,  5.4996e-01,  5.5639e-02,  8.2757e-01,\n",
      "          7.2452e-01,  5.4558e-01,  6.2077e-02, -4.3428e-02,  4.6131e-01,\n",
      "         -5.0858e-01,  5.3003e-01,  2.8836e-01,  3.3764e-01, -6.6761e-01,\n",
      "          5.4648e-01, -4.8900e-03,  1.9758e-01,  4.2248e-01,  4.3940e-01,\n",
      "          1.6686e-01,  1.4027e-01,  5.5733e-01,  4.1427e-01,  2.4610e-01,\n",
      "          2.0090e-03, -2.4155e-01,  7.3063e-01,  1.2839e+00,  4.2851e-01,\n",
      "         -1.7495e-01,  6.4520e-01,  4.5039e-01,  1.3702e-01,  1.0775e-01,\n",
      "          5.0876e-01, -1.8366e-01,  2.1371e-01, -1.2289e-01,  5.7464e-01,\n",
      "          1.8295e-01, -4.0935e-01,  1.9956e-01,  4.7766e-01, -3.1076e-02,\n",
      "          4.2105e-01,  2.3200e-01,  8.1797e-01, -5.1198e-01, -2.6592e-01,\n",
      "          5.8837e-02,  5.9086e-01,  2.3069e-01, -2.6189e-01,  1.0461e+00,\n",
      "          7.8996e-01,  7.0679e-01,  5.8270e-01,  1.0752e+00, -2.3154e-02,\n",
      "          6.3590e-01,  2.6932e-01,  7.7292e-01,  4.1244e-01, -1.0105e-01,\n",
      "          8.0925e-02,  5.1133e-01,  1.7203e-01,  6.5474e-01,  1.7258e-01,\n",
      "          4.8737e-01,  6.4827e-01, -9.8744e-01,  6.3798e-01,  8.6193e-01,\n",
      "         -6.3261e-01,  2.3675e-01,  5.9094e-01,  1.5871e-01,  3.2860e-01,\n",
      "         -2.2152e-01, -6.1790e-01, -5.1246e-02,  3.5952e-01,  6.5074e-01,\n",
      "          5.1598e-01,  4.3954e-02,  4.9811e-01, -2.0424e-01, -4.3569e-01,\n",
      "         -7.9909e-01, -9.3760e-01, -7.4082e-01,  7.5071e-01, -1.2698e+00,\n",
      "         -1.1977e+00, -1.0342e+00, -8.6771e-01, -1.2614e+00, -5.4103e-01,\n",
      "         -4.3869e-01,  5.7399e-01,  6.7243e-01, -2.5940e-01,  1.2048e-01,\n",
      "          7.6808e-01, -1.4550e-01, -2.3480e-01, -4.6276e-01, -1.2684e+00,\n",
      "         -8.6338e-01, -9.4509e-01, -3.0300e-01, -6.3777e-01, -1.1732e+00,\n",
      "         -1.3338e+00, -8.4950e-01, -1.4032e+00, -5.6780e-01, -1.7689e-01,\n",
      "         -1.8245e+00, -5.6100e-01, -1.1268e-01, -4.4585e-01, -9.0805e-01,\n",
      "         -5.7353e-01,  6.5283e-02, -6.0601e-01, -1.4140e+00, -4.9763e-01,\n",
      "          4.6759e-01, -5.3370e-02, -1.9425e-01,  2.4423e-01,  5.9249e-01,\n",
      "         -3.1859e-01, -6.6782e-01, -9.5981e-01, -1.0423e+00, -7.6812e-01,\n",
      "         -1.5370e+00, -1.1913e+00, -1.4110e+00, -1.3706e+00, -1.5504e+00,\n",
      "         -1.5677e+00, -1.2240e+00,  7.7098e-02, -6.4647e-02, -5.1345e-01,\n",
      "         -3.0281e-01, -3.8919e-01,  1.2375e-01,  2.6172e-01, -9.1068e-01,\n",
      "         -9.3252e-01, -1.5149e+00, -1.5504e-01,  5.6998e-01, -1.0879e+00,\n",
      "         -5.7160e-01,  7.8481e-01, -5.6800e-01, -1.4723e+00, -9.8716e-01,\n",
      "          7.7086e-01, -6.9639e-01, -1.8902e+00, -2.0953e-01, -1.3555e+00,\n",
      "         -1.3064e+00, -2.1337e+00, -1.1787e+00, -6.3298e-01, -7.3918e-01,\n",
      "          4.4161e-01,  1.0486e+00, -1.3480e-01,  5.1152e-01,  2.9491e-01,\n",
      "         -5.4634e-01,  3.5306e-01,  3.5847e-03,  4.4379e-01, -9.5145e-01,\n",
      "         -3.8341e-01, -1.1072e+00, -4.6963e-01, -8.8824e-01, -7.6678e-01,\n",
      "         -8.0677e-01, -1.9552e-01, -3.7005e-01, -1.6848e-01, -2.0430e-01,\n",
      "         -1.2976e+00, -8.5222e-01,  1.3237e-02, -5.8123e-01, -6.8998e-01,\n",
      "         -4.4748e-02, -6.6519e-01, -3.1519e-01, -6.3323e-01, -9.7568e-01,\n",
      "         -5.6703e-01, -1.1721e+00, -9.5832e-01, -9.1926e-01, -4.5218e-01,\n",
      "          3.2429e-01,  7.8574e-02, -1.4905e+00, -1.5659e+00, -3.0393e-01,\n",
      "          3.6603e-01, -1.2506e+00, -5.5432e-01,  5.1513e-01, -1.1912e-01,\n",
      "         -7.1164e-01,  9.6163e-01,  1.8362e-01, -2.2707e+00, -1.8108e+00,\n",
      "         -3.8550e-01, -2.7946e-01, -1.5705e-01, -1.3200e-01,  1.0866e+00,\n",
      "         -3.5322e-01,  1.3840e-01,  1.8573e+00,  1.0008e+00,  3.2680e-01,\n",
      "          8.8080e-01, -1.9255e-02,  3.2521e-01,  3.2732e-01,  1.0241e+00,\n",
      "          8.2983e-01,  1.2418e+00,  5.1908e-03,  4.4635e-01,  3.9326e-01,\n",
      "         -8.9639e-01, -1.0347e-01,  1.5062e+00,  1.7500e+00,  7.8283e-01,\n",
      "         -6.3250e-01, -1.1093e-01,  2.5355e-01,  6.5897e-01,  1.4232e-01,\n",
      "          9.1069e-01, -1.6445e-01, -1.9613e-01,  4.6015e-01,  2.3086e-01,\n",
      "          9.1083e-01,  3.5347e-01,  1.4886e-01, -7.1096e-01, -1.3287e-01,\n",
      "          3.4219e-01,  1.8933e-01,  1.8458e+00,  4.6374e-01, -8.4082e-01,\n",
      "         -3.4146e-01,  2.9095e-02,  3.9798e-01, -2.2555e-01, -2.0612e-01,\n",
      "          6.1457e-01,  1.5626e+00,  1.4323e+00, -3.1388e-01,  8.3977e-01,\n",
      "         -7.0971e-01,  2.8165e-01,  1.2457e+00,  2.4139e+00,  1.0752e+00,\n",
      "         -2.7125e-01, -9.2876e-01, -6.7565e-02,  1.6055e-01,  1.4897e+00,\n",
      "          1.3612e+00,  7.0930e-01,  1.5254e-01,  9.8225e-01, -3.0605e-01,\n",
      "          1.6555e-01,  3.0497e-02,  2.7102e-01,  3.0371e-01,  5.3221e-01,\n",
      "          7.3469e-02,  1.5102e-01,  4.8965e-01, -8.4735e-01, -1.1678e+00,\n",
      "         -1.5513e-01, -1.1822e-01,  1.2176e+00,  1.4486e+00,  1.2399e+00,\n",
      "          4.6332e-01,  1.0215e+00,  3.2421e-01, -1.4038e+00,  1.0786e+00,\n",
      "         -1.1010e+00, -9.8898e-02, -2.3737e-01,  8.8734e-03,  1.3133e+00,\n",
      "         -1.8437e+00,  3.3619e-01,  9.0381e-01,  3.8702e-01,  9.7022e-01,\n",
      "          1.1321e+00,  1.0301e+00,  4.9560e-01,  5.5421e-01,  3.3180e-01,\n",
      "         -1.0386e+00, -7.2901e-01,  7.4686e-01,  3.2501e-01,  9.8723e-01,\n",
      "          1.9111e+00,  1.8602e-01,  1.1430e-01,  1.3555e+00,  6.6588e-01,\n",
      "         -9.2195e-01,  4.9087e-01,  9.0268e-01,  1.4411e+00,  1.5844e-01,\n",
      "         -6.2772e-01, -3.8152e-02, -4.5167e-01,  6.2916e-01,  3.8568e-02,\n",
      "          1.2013e+00,  5.1808e-01,  6.8528e-02, -9.5108e-01,  4.3473e-01,\n",
      "         -2.6449e-01, -3.7852e-01, -7.6207e-01,  3.3590e-01,  1.3403e+00,\n",
      "         -1.1001e+00,  1.5785e+00,  9.6003e-01,  1.0971e+00,  7.2979e-01,\n",
      "          9.6157e-01,  4.8313e-01, -1.8082e+00, -1.2860e+00, -2.1462e-01,\n",
      "         -4.7413e-01, -1.1998e-01,  6.9453e-01, -3.2978e-01, -1.2418e+00,\n",
      "         -4.7058e-01,  4.2416e-01,  2.8024e-01,  1.1437e+00,  8.2397e-01,\n",
      "         -4.0016e-02, -1.7252e-01,  9.5836e-01,  2.6716e-02, -1.6129e+00,\n",
      "         -7.8926e-01,  1.7452e-01,  1.0394e+00,  2.5518e-01, -4.0872e-01,\n",
      "          1.3596e+00,  1.0075e-01,  7.3348e-01, -4.8901e-01,  5.9556e-01,\n",
      "         -2.7062e-01, -9.4853e-01,  1.1767e+00,  2.6646e-01,  7.6248e-02,\n",
      "          4.7305e-01, -1.7890e-01,  9.2579e-01,  4.4424e-01,  9.6325e-01,\n",
      "          8.2236e-01, -1.9857e-01,  1.6603e+00,  8.4710e-01,  1.1228e+00,\n",
      "         -2.3375e-01,  5.6188e-01, -5.5497e-01,  8.5438e-01,  2.8094e-01,\n",
      "         -1.7594e-01,  1.0679e+00, -1.5040e-01, -5.4928e-01,  1.1166e+00,\n",
      "          1.9402e+00, -1.3477e-01, -5.5280e-02, -4.7931e-01,  3.3895e-01,\n",
      "          2.6204e-01,  1.4379e+00, -2.2205e-01,  7.1740e-01,  8.6806e-02,\n",
      "          8.6004e-01,  4.3326e-01, -6.4137e-01,  8.2681e-01,  7.0358e-02,\n",
      "          3.5338e-01,  9.4103e-01,  5.5339e-01,  1.6502e+00,  6.2693e-01,\n",
      "          1.0111e+00,  9.2948e-01,  5.4516e-01,  3.8237e-01,  3.4411e-01,\n",
      "         -1.0048e+00,  1.3444e+00, -8.0628e-02, -9.0740e-01,  3.8269e-01,\n",
      "         -1.9405e-02,  8.0749e-01,  7.2884e-01,  1.3150e+00, -6.0656e-02,\n",
      "          3.8065e-01,  1.3399e+00,  6.0464e-01,  6.8498e-01,  1.5634e-01,\n",
      "         -1.7211e+00,  1.3761e+00,  1.0009e-01,  1.5429e+00,  8.7002e-01,\n",
      "         -8.1073e-01,  7.7690e-01,  5.0668e-01, -9.2905e-01, -1.5518e+00,\n",
      "          1.1983e+00,  3.2230e-01,  7.6771e-01,  7.3014e-01,  4.9354e-02,\n",
      "          6.3352e-01, -1.3039e-02,  3.6740e-01, -2.1042e-02,  3.6351e-01,\n",
      "         -1.5675e-01, -7.7675e-01, -9.5649e-02, -1.0066e+00,  1.0237e+00,\n",
      "          1.8175e-01,  1.3304e+00,  4.2809e-01, -6.8022e-01, -6.4217e-01,\n",
      "          2.4725e-01, -3.3334e-02, -2.5972e-01,  6.5710e-01,  1.5214e+00,\n",
      "         -8.7449e-01,  1.7573e+00,  8.3068e-01,  1.0170e+00,  2.2614e-02,\n",
      "          6.7821e-01,  6.4200e-01, -5.8491e-01,  3.8890e-01,  8.8891e-01,\n",
      "         -1.1650e+00, -1.3661e-01, -9.6309e-01,  1.5089e-02, -9.5445e-01,\n",
      "         -5.3564e-01,  1.1512e+00,  7.9598e-01,  6.1387e-01, -8.1948e-01,\n",
      "          7.3449e-01,  1.2676e+00, -2.8763e-02, -2.6331e-01,  8.2310e-01,\n",
      "          1.5467e+00, -2.5687e-01, -1.3101e-01,  3.4353e-01,  6.0607e-01,\n",
      "         -2.4383e-01, -5.6835e-01,  2.8713e-01,  7.9744e-01,  2.3503e-01,\n",
      "          1.2173e+00,  8.1859e-01,  2.1775e-01, -4.8302e-01,  3.1229e-01,\n",
      "         -3.9495e-01,  6.1709e-01, -6.7768e-01, -3.1093e-01,  5.9778e-01,\n",
      "          2.7685e-01, -6.9194e-02,  1.4203e+00,  2.4360e-01, -6.0441e-01,\n",
      "          1.2362e+00, -5.6466e-01,  1.6325e-01,  1.3064e+00, -6.6195e-01,\n",
      "          3.5861e-01,  2.2354e+00, -5.0188e-01,  1.7542e+00, -1.4688e+00,\n",
      "          8.6627e-02, -2.5453e-01,  7.4321e-01,  9.2457e-01, -2.8316e-03,\n",
      "          1.1869e+00, -2.0923e-01,  2.6734e-01,  1.5640e-01,  9.8039e-01,\n",
      "          3.2953e-01,  8.2115e-02,  4.1040e-01,  7.1625e-01,  1.3488e+00,\n",
      "          1.7446e-01,  2.0579e-01,  3.1222e-01,  3.6740e-01,  1.0073e+00,\n",
      "         -4.8878e-01,  9.5211e-01, -3.0348e-01,  1.5154e+00,  2.3003e-01,\n",
      "         -3.3522e-01,  9.1343e-01,  7.3209e-01,  1.0908e+00,  1.4525e+00,\n",
      "          8.3693e-01,  5.7469e-01,  5.0456e-01,  2.0910e-02,  1.4699e+00,\n",
      "          3.8783e-01,  2.1410e-01,  1.0983e+00,  8.6650e-01,  9.5875e-01,\n",
      "          2.9284e-01,  5.1028e-01,  6.0608e-01,  1.0928e+00, -3.9729e-01,\n",
      "         -7.6510e-01, -7.2803e-01,  1.1419e+00,  8.1252e-01,  1.4713e+00,\n",
      "          4.4672e-01,  4.4295e-01,  1.0560e+00,  2.3562e-01, -3.1644e-02,\n",
      "          6.4481e-01,  1.0544e+00,  1.5697e+00,  7.8383e-01, -1.7664e-01,\n",
      "         -1.5330e-02,  8.9752e-01,  5.8373e-01, -8.2219e-01,  2.9038e-01,\n",
      "         -7.2871e-01,  3.6138e-01, -1.1801e+00, -1.0424e+00,  6.8392e-01,\n",
      "          1.3997e+00,  6.0470e-02,  3.2684e-01,  1.3473e+00,  1.0340e-01,\n",
      "         -1.6834e-01,  1.1725e+00, -9.6350e-02,  1.6055e+00, -9.2337e-01,\n",
      "         -3.7408e-01,  5.6398e-01, -8.9083e-01,  1.7474e+00,  6.6954e-01,\n",
      "         -1.3882e+00, -7.9868e-01,  6.3178e-01,  5.3336e-01,  7.3435e-01,\n",
      "         -9.1514e-01,  6.2080e-01,  8.9482e-01,  1.6968e+00, -4.9353e-01,\n",
      "          1.0605e+00,  2.5499e-01, -5.0343e-01, -1.1059e+00,  1.6723e-01,\n",
      "          3.9795e-01,  2.0096e+00,  1.9211e+00,  8.0884e-01, -3.7655e-01,\n",
      "          1.2600e+00,  3.0553e-01,  3.2290e-01,  5.0240e-01,  5.6328e-01,\n",
      "          1.6434e+00,  4.9244e-01, -1.7202e-01,  6.5068e-01,  9.8058e-01,\n",
      "          1.0462e+00,  1.6637e+00,  1.7170e+00, -6.9770e-01, -2.9873e-01,\n",
      "          1.0618e+00, -3.3836e-01, -3.8304e-01, -3.2937e-01,  9.6524e-01,\n",
      "          2.9841e-01,  1.0847e+00,  1.0848e+00, -3.1519e-01, -1.2205e-01,\n",
      "          7.1291e-01,  4.3417e-01, -2.9899e-02,  1.6064e+00, -4.4949e-01,\n",
      "          1.0770e+00, -1.2015e+00,  1.0847e+00, -1.2585e+00, -2.3286e+00,\n",
      "          2.8044e-01,  1.4689e+00, -5.2993e-02, -9.6172e-02,  1.4690e+00,\n",
      "          1.1880e+00, -3.0645e-01,  1.0322e+00,  9.4854e-01, -5.1343e-02,\n",
      "          1.5401e-01, -6.8821e-01, -3.1652e-01, -1.0872e+00,  5.1720e-01,\n",
      "         -1.0870e-01,  2.1889e-01,  6.1213e-01,  7.4877e-02, -1.1529e+00,\n",
      "         -6.2087e-01,  8.8192e-01,  5.6371e-01,  1.8823e+00,  1.9692e+00,\n",
      "         -1.0610e+00, -4.5313e-01,  1.7598e+00,  8.7966e-01,  1.0487e+00,\n",
      "         -6.6598e-03, -3.3347e-01,  1.3910e+00, -9.7612e-01,  1.1124e+00,\n",
      "          9.9729e-01,  9.5747e-01,  8.5163e-01, -4.2963e-01, -1.7876e+00,\n",
      "         -4.4714e-01,  4.1014e-01,  3.0279e-01,  7.6339e-01, -3.8955e-03,\n",
      "         -8.9113e-02,  1.0489e+00, -7.4335e-01,  7.5014e-01, -3.6709e-01,\n",
      "         -7.6629e-01, -7.3839e-01, -6.7807e-01, -1.6230e-01,  1.5685e+00,\n",
      "          2.4234e-02,  8.1602e-02,  4.6082e-01, -1.6481e+00,  5.7992e-02,\n",
      "         -4.4994e-01,  4.6108e-01,  4.5479e-01,  2.6797e-01,  8.1187e-02,\n",
      "         -1.8282e-01, -3.5585e-01, -1.6189e-01,  3.7040e-01, -2.0074e-01,\n",
      "         -4.2589e-01, -9.3048e-01,  3.4590e-01,  6.4767e-01, -1.4186e-01,\n",
      "          4.5886e-02, -6.0413e-01, -7.7626e-01,  2.6892e-01,  5.8521e-01,\n",
      "         -8.1231e-01, -9.0642e-02, -4.3105e-01,  4.1181e-02, -8.8270e-01,\n",
      "          1.8703e-01,  2.0443e-01, -2.8088e-01, -6.2751e-01, -1.1359e+00,\n",
      "         -2.2707e-01,  5.7443e-01, -4.0790e-01,  8.7274e-01,  3.1238e-02,\n",
      "         -2.1358e-01,  1.1214e+00, -4.1328e-01, -3.5832e-01, -1.9903e+00,\n",
      "          8.7007e-01, -1.6535e+00,  1.9886e-01,  1.1055e-01, -9.7313e-01,\n",
      "         -6.4068e-01,  2.9685e-01,  5.2086e-01, -5.1534e-01, -1.2214e+00,\n",
      "         -1.3213e+00, -2.1219e+00,  1.5188e+00, -3.3112e-01, -1.0375e+00,\n",
      "         -4.6405e-01, -1.3567e+00, -1.1361e+00, -1.9322e+00, -6.6545e-01,\n",
      "         -4.6107e-01, -1.1217e-02, -6.3281e-01,  1.5488e+00,  7.2147e-01]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction = model(data)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward propagation\n",
    "    - Use the model prediction to calculate the error (`loss`)\n",
    "    - Next step is to backpropagate this error through the networ\n",
    "    - Back propagation is kicked off when we call `.backward()` on the error tensor\n",
    "    - Autograd then calculates ad stores the gradients for eaeh model parameter in the parameter's `.grad` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-491.6093, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize\n",
    "    - Next step is to load an optimizer, in this case SGD with a learning rate of 0.01 and `momentum` of 0.9\n",
    "    - Register all the parameters of the model in the optimizer\n",
    "    - SGD = Stochastic Gradient Descent\n",
    "    - Momentum or SGD with momentum is method which helps accelerate gradients vectors in the right directions, thus leading to faster converging. Specifically it helps the model exit the local min/max to find the absolute min/max\n",
    "    - Momentum = data from exponentially weighed averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "print(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step\n",
    "    - Finally, call `.step()` to initiate gradient descent (next epoch)\n",
    "    - The optimizer adjusts each parameter by its gradient stored in `.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "optim.step()\n",
    "\n",
    "print(optim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
