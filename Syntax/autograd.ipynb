{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background \n",
    "- Neural Networks (NN) are a collection of nested functions that are executed on some input data. These functions are defined by parameters (consisting of weights and biases), which in PyTorch are stored in tensors\n",
    "- Training a NN happens in 2 steps:\n",
    "    + Forward Propagation\n",
    "        In forward prop, the NN makes its best guest about the correct output. It runs the input data through eaech of its functions to make this guess\n",
    "    + Backward Propagation\n",
    "        In backdrop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collection the derivatives of the error with respect to the parameters of the functions (gradient), and optimizing the parameters using gradient decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage in PyTorch\n",
    "- Look at an example in a single training step\n",
    "- Load a pretrained resnet18 model from `torchvision`\n",
    "- Create a random data tensor to represent a single image with 3 channels, and height & width of 64, and its corresponding label initialized to some random values.\n",
    "- Label in pretrained model has shape (1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6251, 0.7598, 0.4248,  ..., 0.7573, 0.5613, 0.7866],\n",
      "          [0.5035, 0.8779, 0.4713,  ..., 0.5650, 0.6767, 0.8562],\n",
      "          [0.2863, 0.4470, 0.3397,  ..., 0.8105, 0.2327, 0.5996],\n",
      "          ...,\n",
      "          [0.9362, 0.1714, 0.4865,  ..., 0.9688, 0.0949, 0.4427],\n",
      "          [0.3287, 0.8217, 0.0116,  ..., 0.2986, 0.4110, 0.5621],\n",
      "          [0.6824, 0.1261, 0.5794,  ..., 0.8098, 0.7799, 0.3102]],\n",
      "\n",
      "         [[0.0841, 0.5695, 0.0147,  ..., 0.7684, 0.3000, 0.0754],\n",
      "          [0.0843, 0.9398, 0.8769,  ..., 0.7375, 0.8783, 0.9871],\n",
      "          [0.2835, 0.3574, 0.5431,  ..., 0.3162, 0.2763, 0.7701],\n",
      "          ...,\n",
      "          [0.1786, 0.8331, 0.3787,  ..., 0.0926, 0.8486, 0.0233],\n",
      "          [0.1115, 0.1803, 0.2837,  ..., 0.4260, 0.9318, 0.4296],\n",
      "          [0.9288, 0.6176, 0.0831,  ..., 0.7140, 0.6532, 0.1884]],\n",
      "\n",
      "         [[0.8207, 0.5359, 0.4929,  ..., 0.3287, 0.2187, 0.8798],\n",
      "          [0.9500, 0.4392, 0.2973,  ..., 0.4105, 0.7287, 0.3486],\n",
      "          [0.7781, 0.5383, 0.5283,  ..., 0.0196, 0.9474, 0.9446],\n",
      "          ...,\n",
      "          [0.6624, 0.6032, 0.9071,  ..., 0.8141, 0.8610, 0.9812],\n",
      "          [0.4574, 0.3693, 0.9282,  ..., 0.8919, 0.2617, 0.0041],\n",
      "          [0.4082, 0.0593, 0.6426,  ..., 0.2155, 0.9025, 0.6183]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foward pass\n",
    "- Run input data through the model through each of its layers to make a prediction\n",
    "- This is a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.4223e-01, -2.6312e-01, -6.5392e-01, -1.2413e+00, -5.4822e-01,\n",
      "         -3.9621e-02, -3.0948e-01,  3.4789e-01,  2.7725e-01, -8.5060e-01,\n",
      "         -1.0082e+00, -7.6116e-01, -2.4797e-01, -9.9563e-01, -9.9884e-01,\n",
      "         -6.9203e-01, -7.0128e-01, -1.0978e-01, -1.9117e-01, -3.3525e-01,\n",
      "         -1.2137e+00, -3.9148e-01, -9.2566e-01,  4.5564e-01, -7.9351e-01,\n",
      "         -8.5201e-01, -5.2296e-01, -7.1877e-01, -5.4128e-01, -2.3017e-02,\n",
      "         -6.0513e-01, -5.8876e-01, -2.6143e-01, -3.6393e-01, -5.2522e-01,\n",
      "         -1.9887e-01,  6.7129e-01, -5.5879e-01, -3.5362e-01, -5.0790e-02,\n",
      "         -5.1483e-01, -8.0781e-01, -1.1929e+00, -4.4078e-01, -2.7278e-01,\n",
      "         -3.9669e-01, -3.5095e-01, -2.4646e-01, -1.1784e+00, -1.1774e+00,\n",
      "         -5.1554e-01,  5.2721e-01, -2.9010e-01, -5.0848e-01, -3.9779e-01,\n",
      "         -8.6925e-01, -4.9056e-01, -1.3593e+00, -4.5141e-01, -2.3684e-01,\n",
      "          6.7086e-01, -6.2189e-02, -9.8641e-02, -1.3104e-01, -6.5366e-01,\n",
      "         -2.2720e-01, -4.2291e-01, -2.0572e-01, -8.2833e-01, -1.1217e+00,\n",
      "         -1.3764e+00,  2.4705e-01, -1.2049e+00, -2.1890e-01, -8.5242e-01,\n",
      "         -1.3692e+00,  1.3779e-01, -5.7808e-01,  3.6628e-01,  2.0216e-01,\n",
      "         -7.6779e-01, -1.3246e+00,  1.1260e-01, -7.6352e-01, -4.2154e-01,\n",
      "          3.0458e-01,  1.7746e-01,  4.7427e-01, -9.5539e-02, -4.6911e-01,\n",
      "         -1.1369e+00, -1.2230e+00, -2.0828e+00, -3.4830e-01,  4.4232e-01,\n",
      "         -1.9497e+00, -6.5229e-01, -3.8061e-01, -1.3809e+00, -2.6238e-01,\n",
      "         -1.4406e+00, -1.2113e+00, -9.4997e-01, -1.5664e-01,  7.1276e-02,\n",
      "         -5.6663e-01, -6.3102e-01, -1.4594e+00, -9.6523e-01, -1.0840e+00,\n",
      "         -9.5983e-01, -7.0512e-01,  1.2569e+00,  4.6113e-01,  5.2021e-01,\n",
      "         -5.5400e-01, -2.7536e-01, -2.3601e-01,  5.7299e-01, -1.1374e-01,\n",
      "         -7.1297e-01,  2.3761e-01,  4.3769e-01,  4.8675e-01,  1.4284e+00,\n",
      "          3.0049e-02,  3.6401e-01, -1.2446e+00, -1.1504e+00, -8.5225e-01,\n",
      "         -1.5320e+00, -1.4074e+00, -8.3639e-01, -1.2488e+00, -6.3726e-01,\n",
      "         -1.1210e+00, -9.8361e-01, -1.2868e+00, -1.2276e+00, -1.2033e+00,\n",
      "         -1.5776e+00, -1.9481e+00, -2.0940e+00, -1.8697e+00, -4.7449e-01,\n",
      "         -6.4571e-01, -9.3348e-01, -2.1213e+00, -1.4003e+00, -1.1754e+00,\n",
      "          1.4124e-01,  1.6568e+00, -1.1284e+00, -5.7970e-01, -4.0439e-01,\n",
      "          1.8509e-02, -2.9706e-01,  2.8839e-02,  3.7838e-01,  1.4747e-01,\n",
      "          5.3360e-01,  2.5369e-01,  5.6137e-02,  9.5620e-02,  3.2638e-01,\n",
      "         -2.4098e-01, -4.1081e-01, -6.1878e-01,  1.9544e-01, -3.8905e-01,\n",
      "         -4.6248e-01,  6.4650e-01,  1.6349e-01,  2.0137e-01,  4.1894e-01,\n",
      "         -1.0251e+00, -4.2079e-02, -3.3736e-01,  5.3865e-01,  5.5588e-01,\n",
      "          4.4269e-01, -2.5484e-02,  5.0430e-01, -2.6351e-02,  3.0899e-01,\n",
      "          5.7631e-01,  6.4696e-01,  2.0674e-01,  1.6721e-01,  4.2296e-01,\n",
      "         -7.0131e-01,  5.4600e-02,  2.2385e-01,  5.2993e-01, -7.9886e-01,\n",
      "          5.8491e-01,  1.4905e-01,  1.4985e-01,  1.5739e-01,  5.2903e-01,\n",
      "         -1.0442e-01,  2.6905e-01,  3.5311e-01,  7.0700e-01, -3.1631e-02,\n",
      "          2.3225e-01, -1.6479e-02,  6.1669e-01,  1.1659e+00,  1.6705e-01,\n",
      "         -3.7538e-01, -4.0842e-02,  5.8691e-01,  2.0756e-01,  2.1211e-01,\n",
      "          4.8668e-01, -4.4335e-02,  3.1957e-01, -3.0517e-01,  5.8443e-01,\n",
      "          1.0292e-01, -1.1353e-01,  8.8462e-02,  7.2537e-01,  4.5893e-01,\n",
      "          2.5639e-01, -1.4257e-01,  9.6431e-01, -6.9480e-01, -2.8660e-01,\n",
      "          1.7510e-02,  4.6942e-01,  4.1831e-01, -1.4955e-01,  5.3208e-01,\n",
      "          9.2496e-01,  3.2579e-01,  3.4545e-01,  3.7640e-01, -3.2211e-02,\n",
      "          5.1686e-01, -1.8281e-01, -4.7286e-02, -7.8715e-02, -5.4374e-01,\n",
      "          3.2330e-01,  2.2936e-01, -2.7778e-01,  7.4825e-01,  3.0511e-01,\n",
      "          5.3832e-01,  6.3925e-01, -9.3975e-01,  4.2309e-01,  4.8840e-01,\n",
      "         -8.4132e-01,  4.0589e-01,  3.4922e-01,  1.2892e-01,  3.3112e-01,\n",
      "         -3.4953e-01, -5.8353e-01, -8.0516e-01,  4.1375e-01,  7.2706e-01,\n",
      "          5.8470e-01,  2.4404e-01,  3.7025e-01, -3.6234e-01, -1.1079e-01,\n",
      "         -6.4097e-01, -9.0000e-01, -4.1968e-01,  6.5052e-01, -1.2564e+00,\n",
      "         -1.0801e+00, -1.1190e+00, -8.7442e-01, -1.2415e+00, -2.5033e-01,\n",
      "         -2.3854e-01,  7.3210e-01,  6.6081e-01, -2.7116e-01,  4.8089e-01,\n",
      "          9.0418e-01, -1.8123e-01, -1.8385e-01, -8.5221e-01, -1.3911e+00,\n",
      "         -1.1705e+00, -1.6613e+00, -6.9778e-01, -8.7758e-01, -1.0382e+00,\n",
      "         -7.5899e-01, -9.0505e-01, -1.3601e+00, -5.3110e-01,  5.7025e-02,\n",
      "         -1.8205e+00, -4.7894e-01, -3.9473e-01, -3.8489e-01, -7.8633e-01,\n",
      "         -7.1917e-01,  5.1320e-01, -8.0507e-01, -9.7669e-01, -3.6605e-01,\n",
      "          4.9477e-01, -1.6759e-01, -2.0485e-01,  5.2098e-01,  9.1794e-01,\n",
      "         -5.3441e-02, -7.5500e-01, -9.2938e-01, -8.9732e-01, -6.6130e-01,\n",
      "         -1.3946e+00, -9.8110e-01, -1.5592e+00, -1.4183e+00, -1.3377e+00,\n",
      "         -1.6815e+00, -1.1891e+00,  3.6586e-01,  3.2028e-01, -4.8805e-01,\n",
      "          7.6487e-02, -1.2103e-01, -4.8717e-02,  2.9610e-01, -6.1072e-01,\n",
      "         -8.4058e-01, -1.7084e+00, -1.8069e-01,  5.3397e-01, -1.5809e+00,\n",
      "         -5.0538e-01,  4.3619e-01, -8.2395e-01, -1.8336e+00, -7.8593e-01,\n",
      "          2.4048e-01, -8.9907e-01, -1.8445e+00, -3.7953e-01, -1.5113e+00,\n",
      "         -1.3737e+00, -2.5241e+00, -1.6813e+00, -9.4554e-01, -1.1467e+00,\n",
      "          5.2209e-01,  1.1012e+00, -3.2733e-01,  4.6175e-01,  3.6041e-01,\n",
      "         -2.2981e-01,  6.6268e-01,  2.0610e-01,  1.9514e-01, -3.9604e-01,\n",
      "         -4.8426e-01, -1.0223e+00, -5.6519e-01, -8.9144e-01, -9.5499e-01,\n",
      "         -9.1306e-01, -7.2322e-01, -6.7767e-01, -1.1571e-01, -5.4371e-01,\n",
      "         -9.5358e-01, -1.4222e+00,  2.1889e-01, -4.0654e-01, -7.5565e-01,\n",
      "          1.3189e-01, -5.8570e-01, -2.8534e-01, -3.8967e-01, -7.4406e-01,\n",
      "         -9.2754e-01, -1.3511e+00, -8.8870e-01, -6.9056e-01, -2.4888e-01,\n",
      "          8.1040e-01,  4.9034e-01, -1.4368e+00, -1.4227e+00,  3.9317e-02,\n",
      "          6.0188e-01, -6.6018e-01, -2.2097e-01,  4.3717e-01,  1.2796e-01,\n",
      "         -6.8056e-01,  9.0751e-01,  7.4923e-02, -1.9902e+00, -1.7008e+00,\n",
      "         -1.6552e-01, -6.5421e-01, -6.3985e-02, -3.5352e-01,  9.5472e-01,\n",
      "         -1.0416e-01,  3.6873e-01,  2.1602e+00,  9.2184e-01,  5.8181e-01,\n",
      "          7.6037e-01, -2.6082e-01,  3.7880e-01,  3.9928e-01,  7.8635e-01,\n",
      "          6.8778e-01,  1.1281e+00, -5.7877e-01,  3.1993e-01,  2.2453e-01,\n",
      "         -7.4198e-01, -1.2942e-01,  1.2976e+00,  1.4793e+00,  2.7030e-01,\n",
      "         -7.5842e-01, -2.3078e-01,  2.9156e-01,  1.0375e+00,  4.3947e-01,\n",
      "          9.0142e-01, -3.3459e-01, -5.3006e-01,  2.2053e-01, -1.8681e-01,\n",
      "          9.2145e-01,  3.4887e-01, -7.8876e-02, -3.8208e-01, -1.7569e-01,\n",
      "          1.5184e-01,  4.9974e-01,  1.5581e+00,  8.3964e-01, -6.0539e-01,\n",
      "         -8.0423e-02,  6.4513e-01,  4.8592e-01, -3.9431e-01, -6.2143e-02,\n",
      "          1.0565e+00,  1.4829e+00,  1.3620e+00,  5.0672e-02,  7.4277e-01,\n",
      "         -7.9584e-01,  4.0979e-01,  1.0544e+00,  2.2649e+00,  7.9697e-01,\n",
      "         -8.8047e-02, -9.0394e-01, -1.7138e-01,  1.1954e-02,  1.1933e+00,\n",
      "          8.8525e-01,  3.8478e-01,  1.3099e-01,  1.3673e+00, -4.6701e-01,\n",
      "          2.6867e-01,  9.8177e-02,  7.1559e-01,  5.9022e-01,  3.0216e-01,\n",
      "          1.4395e-01, -3.8769e-02,  8.8640e-02, -9.4355e-01, -1.5455e+00,\n",
      "          1.5390e-02, -3.5527e-01,  1.3098e+00,  1.5015e+00,  1.2533e+00,\n",
      "          4.6904e-01,  7.8260e-01,  6.8351e-01, -1.4395e+00,  8.8145e-01,\n",
      "         -1.0756e+00, -2.1143e-01, -5.7926e-01, -1.2729e-01,  1.2782e+00,\n",
      "         -1.7026e+00,  6.0501e-01,  8.3600e-01,  7.7680e-01,  8.5989e-01,\n",
      "          1.0925e+00,  8.4884e-01,  5.6235e-01,  5.9194e-01,  4.2979e-01,\n",
      "         -9.6204e-01, -9.3019e-01,  1.0207e+00,  4.1203e-01,  6.3700e-01,\n",
      "          1.5761e+00,  2.2718e-01,  7.9878e-02,  1.1633e+00,  4.3768e-01,\n",
      "         -1.1055e+00,  4.1535e-01,  8.0563e-01,  1.4878e+00,  2.9510e-01,\n",
      "         -7.7297e-01, -2.1516e-01, -3.2046e-01,  3.3419e-01, -2.3238e-01,\n",
      "          1.1011e+00,  3.2626e-01, -7.4430e-02, -9.0954e-01,  6.2612e-01,\n",
      "         -5.3369e-01, -6.3678e-01, -5.9608e-01,  2.1431e-02,  1.1537e+00,\n",
      "         -1.4085e+00,  1.2663e+00,  1.0909e+00,  5.3408e-01,  5.0399e-01,\n",
      "          5.1428e-01,  6.6583e-01, -1.6619e+00, -1.6582e+00,  1.1646e-01,\n",
      "         -6.2464e-01,  4.7599e-02,  7.1401e-01, -3.9077e-01, -1.6104e+00,\n",
      "         -3.5164e-01,  7.2269e-03,  5.1731e-01,  1.1966e+00,  1.1266e+00,\n",
      "         -1.4516e-01, -1.7267e-01,  5.3902e-01,  4.4067e-03, -1.5078e+00,\n",
      "         -5.9101e-01,  1.9445e-01,  9.7021e-01,  2.6485e-01, -3.9362e-01,\n",
      "          1.2204e+00, -5.8433e-02,  8.1789e-01, -1.0225e+00,  5.7289e-01,\n",
      "         -3.1853e-01, -1.0246e+00,  5.3651e-01,  3.9887e-01,  2.3737e-01,\n",
      "          5.2968e-01, -1.0498e-01,  1.1617e+00,  6.8525e-01,  7.5812e-01,\n",
      "          8.5394e-01, -3.2043e-01,  1.5604e+00,  8.7786e-01,  1.2421e+00,\n",
      "         -3.0751e-01,  5.0421e-01, -2.3445e-01,  8.6088e-01,  9.5166e-02,\n",
      "         -8.4192e-01,  9.9355e-01, -1.2354e-01, -8.1103e-01,  1.0057e+00,\n",
      "          2.2861e+00, -4.4369e-01, -4.8940e-01, -8.6175e-01,  3.5977e-01,\n",
      "         -1.3132e-01,  7.7006e-01, -4.3098e-01,  3.7025e-01, -7.9899e-02,\n",
      "          9.1998e-01,  7.6153e-01, -5.4622e-01,  8.3552e-01,  2.6856e-01,\n",
      "          1.1112e-01,  9.2240e-01,  4.4725e-01,  2.0096e+00,  9.2011e-01,\n",
      "          9.3159e-01,  5.4764e-01,  4.1610e-01,  7.2956e-01, -2.5040e-02,\n",
      "         -1.4409e+00,  1.1576e+00, -1.7964e-01, -1.1709e+00,  4.0019e-01,\n",
      "         -1.7419e-01,  1.1082e+00,  5.2702e-01,  1.4722e+00, -4.1070e-01,\n",
      "          2.0652e-01,  1.1792e+00,  1.0649e+00,  4.9520e-01,  1.5904e-01,\n",
      "         -1.5354e+00,  1.2335e+00, -2.7927e-01,  1.1176e+00,  6.0971e-01,\n",
      "         -8.0810e-01,  7.5433e-01,  2.3432e-01, -4.8547e-01, -1.5481e+00,\n",
      "          1.1231e+00,  3.5876e-01,  5.9728e-01,  8.2605e-01,  4.0128e-01,\n",
      "          4.2357e-01,  2.0385e-01,  1.7083e-01, -1.8206e-01,  1.8211e-01,\n",
      "          1.1636e-01, -1.1109e+00,  1.0231e-01, -1.2051e+00,  1.0321e+00,\n",
      "          1.2490e-01,  1.0202e+00,  5.9263e-01, -8.8938e-01, -5.3136e-01,\n",
      "          3.8053e-01, -1.7720e-01, -1.5620e-01,  7.5275e-01,  1.3886e+00,\n",
      "         -3.9330e-01,  1.5545e+00,  1.2675e+00,  6.6510e-01,  4.0021e-01,\n",
      "          7.2742e-01,  5.1574e-01, -4.4830e-01,  3.3909e-01,  8.2399e-01,\n",
      "         -1.4972e+00, -1.3062e-01, -1.1806e+00, -5.6068e-02, -9.2992e-01,\n",
      "         -8.8095e-01,  6.8302e-01,  1.1516e+00,  4.5535e-01, -9.0297e-01,\n",
      "          1.0025e+00,  1.6590e+00, -1.7425e-02, -6.9438e-01,  3.9224e-01,\n",
      "          1.7889e+00, -2.7677e-01, -3.7444e-01,  5.1429e-01,  8.0914e-01,\n",
      "          4.1890e-02, -1.2856e-01,  2.6321e-01,  8.1329e-01,  9.2349e-02,\n",
      "          9.0745e-01,  1.1757e+00,  2.0486e-01, -3.6526e-01,  4.1853e-01,\n",
      "         -5.7008e-01,  8.0437e-01, -7.2357e-01, -2.1885e-01,  7.6412e-01,\n",
      "          5.2043e-01,  2.9925e-02,  1.4415e+00,  2.7277e-01, -6.6580e-01,\n",
      "          1.2717e+00, -1.0015e+00, -4.5629e-02,  1.6977e+00, -6.2027e-01,\n",
      "          3.9186e-02,  2.0094e+00, -6.7152e-01,  1.8701e+00, -1.1677e+00,\n",
      "          2.4967e-01, -2.2633e-01,  1.0490e+00,  8.9742e-01, -4.6518e-01,\n",
      "          1.2591e+00, -1.9702e-01,  6.0421e-01,  4.3629e-01,  7.2982e-01,\n",
      "          8.2033e-02, -2.8055e-01,  6.0555e-01,  7.1937e-01,  1.3695e+00,\n",
      "          4.2290e-01, -3.8001e-01,  1.0353e-01,  6.8165e-01,  9.1893e-01,\n",
      "         -2.9304e-01,  1.1647e+00,  1.0650e-01,  1.3885e+00,  1.0900e-01,\n",
      "          2.4656e-01,  9.9752e-01,  4.9594e-01,  9.0324e-01,  1.3954e+00,\n",
      "          8.2113e-01,  2.8614e-01,  6.8835e-01, -1.0146e-01,  1.1882e+00,\n",
      "          4.1117e-01,  3.2508e-01,  1.7604e+00,  1.0917e+00,  8.0233e-01,\n",
      "          4.7799e-01,  5.5823e-01,  6.3173e-01,  1.2525e+00, -6.1033e-01,\n",
      "         -1.0819e+00, -5.8794e-01,  1.2396e+00,  1.1228e+00,  1.7353e+00,\n",
      "          4.1571e-01,  4.3866e-01,  1.0694e+00,  2.4985e-01, -6.8838e-02,\n",
      "          4.9139e-01,  1.2201e+00,  1.3267e+00,  8.7269e-01,  4.3308e-01,\n",
      "          7.8183e-03,  8.4427e-01,  8.5113e-01, -7.4695e-01,  5.5885e-01,\n",
      "         -7.2711e-01,  2.4969e-01, -1.0496e+00, -1.4039e+00,  1.3023e+00,\n",
      "          1.2547e+00,  1.8204e-01,  3.5709e-01,  1.1686e+00,  6.0663e-02,\n",
      "         -5.2937e-01,  1.1840e+00, -5.5297e-01,  1.7749e+00, -1.1720e+00,\n",
      "          1.6725e-03, -2.0026e-01, -1.3685e+00,  1.9650e+00,  3.7055e-01,\n",
      "         -1.3996e+00, -8.2969e-01,  2.2113e-01,  5.2718e-01,  9.2153e-01,\n",
      "         -6.8898e-01,  3.6110e-01,  7.5764e-01,  1.4388e+00, -1.9266e-01,\n",
      "          1.4256e+00,  2.2330e-01, -7.3160e-01, -1.1101e+00,  9.5966e-02,\n",
      "          6.2962e-01,  1.6396e+00,  1.6448e+00,  1.1038e+00, -4.5928e-01,\n",
      "          1.1704e+00,  4.3959e-01,  4.7233e-01,  3.0493e-01,  6.1140e-01,\n",
      "          1.8383e+00,  6.4817e-01, -5.3726e-01,  2.3940e-01,  6.1372e-01,\n",
      "          8.6296e-01,  1.4607e+00,  1.8697e+00, -7.3607e-01, -4.8101e-01,\n",
      "          7.6108e-01, -7.0836e-01, -5.4849e-01, -2.8828e-01,  1.2389e+00,\n",
      "          2.4032e-01,  1.3907e+00,  8.6890e-01, -6.7263e-02, -4.3786e-01,\n",
      "          3.6950e-01, -8.5742e-02, -1.5635e-01,  1.4331e+00, -5.5648e-01,\n",
      "          6.3218e-01, -1.5095e+00,  1.1630e+00, -1.2882e+00, -1.8513e+00,\n",
      "          1.6980e-01,  1.3755e+00, -2.7972e-02, -1.6168e-01,  1.8053e+00,\n",
      "          1.0965e+00, -1.3310e-01,  9.9181e-01,  1.0548e+00, -8.1042e-02,\n",
      "          3.7906e-02, -3.2825e-02, -3.6496e-01, -9.7115e-01,  2.5237e-01,\n",
      "         -2.8408e-01,  4.5253e-01,  6.7422e-01,  3.4346e-01, -8.4218e-01,\n",
      "         -5.0375e-01,  1.0794e+00,  4.4113e-01,  2.3056e+00,  1.6867e+00,\n",
      "         -9.3265e-01, -5.7489e-01,  1.7886e+00,  4.7075e-01,  1.1983e+00,\n",
      "         -2.9620e-03, -4.7593e-01,  1.1651e+00, -9.6270e-01,  7.6007e-01,\n",
      "          1.2483e+00,  7.4253e-01,  7.8632e-01, -4.1096e-01, -1.9616e+00,\n",
      "         -3.9603e-01, -2.5075e-02,  3.0365e-01,  5.3154e-01,  4.0357e-01,\n",
      "         -7.2847e-02,  1.2099e+00, -4.7809e-01,  4.1151e-01, -2.2343e-01,\n",
      "         -9.9227e-01, -1.1391e+00, -3.9895e-01,  8.7241e-02,  1.6594e+00,\n",
      "         -5.5190e-01, -7.8631e-02,  3.8959e-01, -1.5365e+00, -3.9394e-02,\n",
      "         -3.5582e-01,  9.5179e-01,  7.5101e-01,  4.1384e-01,  2.3277e-01,\n",
      "         -2.3810e-02, -4.0596e-01, -1.5039e-01,  6.1961e-01,  7.8032e-02,\n",
      "         -5.7749e-01, -8.7333e-01,  6.4119e-01,  8.5910e-01, -1.3260e-02,\n",
      "         -9.3282e-03, -5.2989e-01, -2.4948e-01,  2.9563e-01,  6.7407e-01,\n",
      "         -3.5799e-01,  5.2237e-02, -3.0668e-01, -4.3681e-01, -8.0360e-01,\n",
      "          3.5890e-01,  2.0614e-01, -3.4319e-01, -4.0551e-01, -1.1052e+00,\n",
      "         -2.1813e-01,  3.7906e-01, -6.8027e-01,  5.5763e-01, -1.1615e-02,\n",
      "         -2.9587e-02,  1.2629e+00, -3.3460e-01, -1.1028e-01, -2.0999e+00,\n",
      "          1.0755e+00, -1.5717e+00,  3.4662e-01,  8.5982e-02, -4.9060e-01,\n",
      "         -7.5224e-01, -2.4778e-01,  5.9702e-01, -3.3323e-01, -8.5854e-01,\n",
      "         -9.1175e-01, -2.4036e+00,  1.3688e+00, -1.8472e-01, -7.8076e-01,\n",
      "         -1.8927e-02, -9.6600e-01, -6.4905e-01, -2.0293e+00, -6.9933e-01,\n",
      "         -4.4066e-01,  3.9832e-01, -3.3122e-01,  1.2033e+00,  9.5365e-01]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction = model(data)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward propagation\n",
    "- Use the model prediction to calculate the error (`loss`)\n",
    "- Next step is to backpropagate this error through the networ\n",
    "- Back propagation is kicked off when we call `.backward()` on the error tensor\n",
    "- Autograd then calculates ad stores the gradients for eaeh model parameter in the parameter's `.grad` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-503.6377, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize\n",
    "- Next step is to load an optimizer, in this case SGD with a learning rate of 0.01 and `momentum` of 0.9\n",
    "- Register all the parameters of the model in the optimizer\n",
    "- SGD = Stochastic Gradient Descent\n",
    "- Momentum or SGD with momentum is method which helps accelerate gradients vectors in the right directions, thus leading to faster converging. Specifically it helps the model exit the local min/max to find the absolute min/max\n",
    "- Momentum = data from exponentially weighed averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "print(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step\n",
    "- Finally, call `.step()` to initiate gradient descent (next epoch)\n",
    "- The optimizer adjusts each parameter by its gradient stored in `.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "optim.step()\n",
    "\n",
    "print(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation in Autograd\n",
    "- How autograd collects gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tensor a and b\n",
    "- We create 2 tensors `a` and `b` with `requires_grad=True`\n",
    "- This signal to `autograd` that every operation on them should be tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tensor Q from a and b\n",
    "- We create another tensor `Q` from `a` and `b`\n",
    "- Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Q into a scalar\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
